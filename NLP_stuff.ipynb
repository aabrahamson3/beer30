{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gzkOYZafI2px"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gzkOYZafI2px"
   },
   "outputs": [],
   "source": [
    "beers = pd.read_csv('beers-breweries-and-beer-reviews/beers.csv')\n",
    "breweries = pd.read_csv('beers-breweries-and-beer-reviews/breweries.csv')\n",
    "reviews = pd.read_csv('beers-breweries-and-beer-reviews/reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "shuYWYkfJvgk"
   },
   "outputs": [],
   "source": [
    "reviews['text'] = reviews['text'].replace(u'\\xa0\\xa0', '')\n",
    "# subset to only reviews that have a text review\n",
    "text_reviews = reviews.loc[reviews['text'] != '']\n",
    "# subset data to exclude NaN's as well (only losing 164k reviews from the last subset)\n",
    "text_no_nan = text_reviews.loc[text_reviews.smell.isna() == False]\n",
    "# rename column name beer_id to id for easy joining\n",
    "text_no_nan = text_no_nan.rename(columns={'beer_id':'id'})\n",
    "# subset out retired beers\n",
    "current_beers = beers.loc[beers['retired'] == 'f']\n",
    "# merge text_no_nan with beers that are not retired\n",
    "df = pd.merge(text_no_nan, current_beers, on='id')\n",
    "# create a table with average ratings for each beer. Index/ID is the beer id\n",
    "ratings = pd.DataFrame(df.groupby('id')['score'].mean())\n",
    "# add a column tallying the # of reviews for that beer\n",
    "ratings['no_of_ratings'] = df.groupby('id')['score'].count()\n",
    "# subset ratings with only beers that have 10+ ratings\n",
    "ratings = ratings.loc[ratings['no_of_ratings'] > 9]\n",
    "# formatting\n",
    "ratings = ratings.reset_index()\n",
    "ratings = ratings.rename(columns={'score':'avg_score'})\n",
    "# rejoin no of ratings onto df\n",
    "df = df.merge(ratings, how='inner', on='id')\n",
    "# make a dataframe of reviewers by usename, count the number of reviews they made\n",
    "reviewers = pd.DataFrame(df.groupby('username')['id'].count())\n",
    "# make a new feature, the average of all of their scores\n",
    "reviewers['avg_usr_score'] = df.groupby('username')['score'].mean()\n",
    "# subset reviewers to those with 5+ reviews. From 73k users to 25k.\n",
    "reviewers = reviewers.loc[reviewers['id'] > 4] ## MAYBE I CAN PLAY WITH THIS #\n",
    "# formatting \n",
    "reviewers = reviewers.rename(columns={'id':'tot_usr_rvw'})\n",
    "# there's ~1400 users outsides of 2 STDs of the mean score, will subset them out\n",
    "reviewers_sub = reviewers.loc[(reviewers['avg_usr_score'] >= 3.182) &\\\n",
    "                              (reviewers['avg_usr_score'] <= 4.665)]\n",
    "\n",
    "# subset of df with beers that have 10+ reviews, and with reviewers that have 5+ reviews\n",
    "# and an average rating of beers between 3.18 and 4.67\n",
    "df_with_mins = df.merge(reviewers_sub, how = 'inner', on = 'username')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DKB-aoHWJ5wF"
   },
   "source": [
    "Content Based NLP Stuff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the combined text for each beer. this skips most preprocessing below. \n",
    "df_joined = pd.read_pickle('joined_text_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_df = df_joined[['id', 'brewery_id', 'city', 'state', 'country', 'brewery_name']]\n",
    "lookup_dict = lookup_df.set_index('id').to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is each review cleaned for Doc2Vec\n",
    "cleaned_reviews_df = pd.read_pickle('cleaned_reviews_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BLQBIoNLJ8Z6"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "from sklearn.feature_extraction import text\n",
    "from gensim.parsing.preprocessing import STOPWORDS as stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HNsi5cDWKRdc"
   },
   "outputs": [],
   "source": [
    "# subsets reviews df, and then joins all text reviews for each individual beer together\n",
    "df_joined = df_with_mins.copy()\n",
    "df_joined['joined_text'] = df_joined.groupby('id')['text'].\\\n",
    "                               transform(lambda x: ''.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IAh8KmW2KVeL"
   },
   "outputs": [],
   "source": [
    "# removes duplicate beers, and subsets to just beer id, joined_text and rating info\n",
    "# to be cleaned and then joined to beers df\n",
    "df_joined_sub = df_joined[['id', 'joined_text', 'avg_score', 'no_of_ratings']].drop_duplicates(\\\n",
    "                                                                        subset='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JnIVdx1mKXPM"
   },
   "outputs": [],
   "source": [
    "# removes \\xa0 remove text\n",
    "df_joined_sub['joined_text'] = df_joined_sub['joined_text'].apply(lambda x: re.sub\\\n",
    "                                                                  (r'\\xa0', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "breweries_sub = breweries[['id','name', 'city', 'state', 'country']]\n",
    "breweries_sub = breweries_sub.rename(columns={'id':'brewery_id', 'name':'brewery_name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "beers_sub = beers[['id', 'name', 'brewery_id', 'style', 'abv']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "breweries_beer = pd.merge(beers_sub, breweries_sub, on = 'brewery_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = pd.merge(df_joined_sub, breweries_beer, on = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.to_pickle(\"./joined_text_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/sklearn-env/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# make a separate df with each individual review, clean up \\xa0's and then pickle\n",
    "cleaned_reviews = df_with_mins[['id', 'text']]\n",
    "cleaned_reviews['text'] = cleaned_reviews['text'].apply(lambda x: re.sub(r'\\xa0', '', x))\n",
    "# cleaned_reviews.to_pickle(\"./cleaned_reviews_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 0% 16 oz can. Funny story: As I finally walked in the doors after a 45 min wait in line and freezing temps the sweet sound of the Grateful Dead\\'s Sugar Magnolia greeted me from the TreeHouse sound system. The bottom of the can reads: \"Going where the wind goes, bloomin\\' like a red rose\" A white haze to the yellow and golden liquid. Thick and healthy, totally unfiltered. Brawny white foam cap, thick, all-white clumps. Huge lacing left over. The aroma has a very zesty citrus hop effect, mellon and mango, grainy earthiness, tropical fruit blend with a bitter to sweet effect, then a peppery kick at the end. Very aromatic. The flavor is just bursting with complex hops, zesty earthy tones, sweet orange, peppery malt, clean fresh feel and overall vibe. A crispy bite wakes you up, full and lush mouthfeel follows from a totally unfiltered expereince. The feel and flavor finishes with a fun, earthy, zesty dry bite. Tropical juicy, zesty citrus, zippy golden wheat malt, melons, rustic earthiness sums up the taste pretty well. Levels of complexity are deep. It\\'s an interesting ride for sure. Overall, this one stands somewhere near the top of the New England IPA\\'s. '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_reviews.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7kQ3_3M5Kavs"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3171c6d89d40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcount_vect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_vect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_joined_sub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoined_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcos_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/sklearn-env/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1220\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/sklearn-env/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1132\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1134\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mfeature_idx\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_counter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1135\u001b[0m                         \u001b[0mfeature_counter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(stop_words='english')\n",
    "counts = count_vect.fit_transform(df_joined_sub.joined_text)\n",
    "cos_sim = cosine_similarity(counts, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5wEc-zNiKiA2"
   },
   "outputs": [],
   "source": [
    "indices = pd.Series(df_joined_sub.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cos_sim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-d7366677f387>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mrecommendations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeer_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcos_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcos_sim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \"\"\"\n\u001b[1;32m      3\u001b[0m     \u001b[0mTakes\u001b[0m \u001b[0ma\u001b[0m \u001b[0mbeer\u001b[0m \u001b[0mid\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcosine\u001b[0m \u001b[0msimilarty\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0marguments\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mbeers\u001b[0m \u001b[0mclosely\u001b[0m \u001b[0mrelated\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m \u001b[0mbeer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# initializing the empty list of recommended movies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cos_sim' is not defined"
     ]
    }
   ],
   "source": [
    "def recommendations(beer_id, df, cos_sim = cos_sim):\n",
    "    \"\"\"\n",
    "    Takes a beer id and cosine similarty matrix in as arguments and returns beers closely related to the input beer\n",
    "    \"\"\"\n",
    "    # initializing the empty list of recommended movies\n",
    "    recommended_beers = []\n",
    "    \n",
    "    # gettin the index of the movie that matches the title\n",
    "    idx = indices[indices == beer_id].index[0]\n",
    "    \n",
    "    # creating a Series with the similarity scores in descending order\n",
    "    score_series = pd.Series(cos_sim[idx]).sort_values(ascending = False)\n",
    "\n",
    "    # getting the indexes of the 10 most similar movies\n",
    "    top_10_indexes = list(score_series.iloc[1:11].index)\n",
    "    print(top_10_indexes)\n",
    "    # populating the list with the titles of the best 10 matching movies\n",
    "    for i in top_10_indexes:\n",
    "        recommended_beers.append(list(joined_df.name)[i])\n",
    "        \n",
    "    return recommended_beers\n",
    "\n",
    "def tfidf_recs(beer_id, cos_sim = tfidf_cos):\n",
    "    \"\"\"\n",
    "    Takes a beer id and cosine similarty matrix in as arguments and returns beers closely related to the input beer\n",
    "    \"\"\"\n",
    "    # initializing the empty list of recommended movies\n",
    "    recommended_beers = []\n",
    "    \n",
    "    # gettin the index of the movie that matches the title\n",
    "    idx = indices[indices == beer_id].index[0]\n",
    "\n",
    "    # creating a Series with the similarity scores in descending order\n",
    "    score_series = pd.Series(cos_sim[idx]).sort_values(ascending = False)\n",
    "\n",
    "    # getting the indexes of the 10 most similar movies\n",
    "    top_10_indexes = list(score_series.iloc[1:21].index)\n",
    "    \n",
    "    # populating the list with the titles of the best 10 matching movies\n",
    "    for i in top_10_indexes:\n",
    "        recommended_beers.append(list(beers_text.name)[i])\n",
    "        \n",
    "    return beers_text.name[beer_id], recommended_beers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>joined_text</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>no_of_ratings</th>\n",
       "      <th>name</th>\n",
       "      <th>brewery_id</th>\n",
       "      <th>style</th>\n",
       "      <th>abv</th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16302</th>\n",
       "      <td>65010</td>\n",
       "      <td>Consumed 4/13/12 Appearance: Dark caramel/lig...</td>\n",
       "      <td>3.607619</td>\n",
       "      <td>42</td>\n",
       "      <td>Perfect Tin Amber</td>\n",
       "      <td>24488</td>\n",
       "      <td>American Amber / Red Ale</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Tin Roof Brewing Company</td>\n",
       "      <td>Baton Rouge</td>\n",
       "      <td>LA</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                        joined_text  avg_score  \\\n",
       "16302  65010   Consumed 4/13/12 Appearance: Dark caramel/lig...   3.607619   \n",
       "\n",
       "       no_of_ratings               name  brewery_id                     style  \\\n",
       "16302             42  Perfect Tin Amber       24488  American Amber / Red Ale   \n",
       "\n",
       "       abv              brewery_name         city state country  \n",
       "16302  4.5  Tin Roof Brewing Company  Baton Rouge    LA      US  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "RE_PUNCT = re.compile('([%s])+' % re.escape(string.punctuation), re.UNICODE)\n",
    "\n",
    "def preprocess(text):\n",
    "    ls = LancasterStemmer()\n",
    "    # Remove all punctuation and make all lowercase \n",
    "    return ls.stem(RE_PUNCT.sub(\" \", text)).lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOC2VEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec, Phrases\n",
    "from gensim.parsing.preprocessing import STOPWORDS as stop_words\n",
    "from gensim.utils import simple_preprocess\n",
    "from sklearn.feature_extraction import text\n",
    "from nltk.stem.lancaster import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = list('abcdefghijklmnopqrstuvwxyz')\n",
    "numbers = list('0123456789')\n",
    "words = ['oz', 'ml'] # ADD MORE\n",
    "stop_words = stop_words.union(set(letters)).union(set(numbers)).union(set(words))\n",
    "my_stop_words = text.ENGLISH_STOP_WORDS.union(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Phrases to let the model detect bigrams\n",
    "# bigram = Phrases(map(preprocess, df_sub.text.tolist()),max_vocab_size=10000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(text):\n",
    "    # uses gensim simple_preprocess and then removes stop words\n",
    "    simple = simple_preprocess(text)\n",
    "    result = [word for word in simple if not word in my_stop_words]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes the document and 'text' as arguments\n",
    "# makes words lowercase and splits them, and then adds the beer id as tag\n",
    "# returns as TaggedDocument\n",
    "def tag_docs(docs):\n",
    "    results = docs.apply(lambda r: TaggedDocument(words=preprocessor(r['text']), tags=[r['id']]), axis=1)\n",
    "    return results.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsetting for a test\n",
    "df_sub = cleaned_reviews_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process reviews, turn into list of TaggedDocument objects, with beer id as tag\n",
    "tagged_docs = tag_docs(cleaned_reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/sklearn-env/lib/python3.7/site-packages/gensim/models/doc2vec.py:574: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    }
   ],
   "source": [
    "## Use format like this \n",
    "\n",
    "model = Doc2Vec(dm=0, dbow_words=1, min_count=4, negative=3,\n",
    "                hs=0, sample=1e-4, window=5, size=100, workers=8)\n",
    "\n",
    "model.build_vocab(tagged_docs, progress_per = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "class EpochLogger(CallbackAny2Vec):\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_begin(self, model):\n",
    "        print(\"Epoch #{} start\".format(self.epoch))\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        print(\"Epoch #{} end\".format(self.epoch))\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0 start\n",
      "Epoch #0 end\n",
      "Epoch #1 start\n",
      "Epoch #1 end\n",
      "Epoch #2 start\n",
      "Epoch #2 end\n",
      "Epoch #3 start\n",
      "Epoch #3 end\n",
      "Epoch #4 start\n",
      "Epoch #4 end\n",
      "Epoch #5 start\n",
      "Epoch #5 end\n"
     ]
    }
   ],
   "source": [
    "epoch_logger = EpochLogger()\n",
    "model.train(tagged_docs, total_examples=model.corpus_count, epochs=6, callbacks=[epoch_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/sklearn-env/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similar_by_vector` (Method will be removed in 4.0.0, use self.wv.similar_by_vector() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('effervescent', 0.8132021427154541),\n",
       " ('lively', 0.8083217144012451),\n",
       " ('fizziness', 0.7874601483345032),\n",
       " ('carbonation', 0.7864266037940979),\n",
       " ('effervesence', 0.7799913883209229),\n",
       " ('active', 0.777531087398529),\n",
       " ('sparkly', 0.7369555234909058),\n",
       " ('spritzy', 0.731114387512207),\n",
       " ('bubbliness', 0.726111114025116),\n",
       " ('liveliness', 0.7169278264045715)]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similar_by_vector('effervescence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('d2v-6epoch.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_word2vec_format('d2v-format', doctag_vec= True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the above but trying it to return a dict\n",
    "def location_filter(ranked_beers, state, city, n):\n",
    "\n",
    "    located_brewery = {}\n",
    "    # state = 'CA'\n",
    "    # city = 'Los Angeles'\n",
    "    counter = 0\n",
    "\n",
    "    for beer in ranked_beers:\n",
    "        if counter < n:\n",
    "            dict_state = lookup_dict[beer[0]]['state']\n",
    "            dict_city = lookup_dict[beer[0]]['city']\n",
    "            brewery_id = lookup_dict[beer[0]]['brewery_id']\n",
    "            brewery_name = lookup_dict[beer[0]]['brewery_name']\n",
    "            if (dict_state == state) and (dict_city == city):\n",
    "        #             print(beer_breweries_lookup[beer[0]])\n",
    "                print(beer[0])\n",
    "                if brewery_id in located_brewery:\n",
    "                    continue\n",
    "                else:  \n",
    "                    located_brewery[brewery_id] = brewery_name\n",
    "                counter += 1\n",
    "    return located_brewery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = model['fruity']\n",
    "d2v_test = model.docvecs.most_similar([vec], topn=3000)\n",
    "d2v_test;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89445\n",
      "92787\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "74560",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-155-4f3332829560>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlocation_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md2v_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'OR'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Portland'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-140-656c275fbdb3>\u001b[0m in \u001b[0;36mlocation_filter\u001b[0;34m(ranked_beers, state, city, n)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbeer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mranked_beers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mdict_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbeer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mdict_city\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbeer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'city'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mbrewery_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbeer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'brewery_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 74560"
     ]
    }
   ],
   "source": [
    "location_filter(d2v_test, 'OR', 'Portland', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing d2v beer_ids to check if real\n",
    "d2v_beers = [beer[0] for beer in d2v_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "NLP_stuff.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
