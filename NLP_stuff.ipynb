{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gzkOYZafI2px"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "beers = pd.read_csv('beers-breweries-and-beer-reviews/beers.csv')\n",
    "breweries = pd.read_csv('beers-breweries-and-beer-reviews/breweries.csv')\n",
    "reviews = pd.read_csv('beers-breweries-and-beer-reviews/reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "shuYWYkfJvgk"
   },
   "outputs": [],
   "source": [
    "reviews['text'] = reviews['text'].replace(u'\\xa0\\xa0', '')\n",
    "# subset to only reviews that have a text review\n",
    "text_reviews = reviews.loc[reviews['text'] != '']\n",
    "# subset data to exclude NaN's as well (only losing 164k reviews from the last subset)\n",
    "text_no_nan = text_reviews.loc[text_reviews.smell.isna() == False]\n",
    "# rename column name beer_id to id for easy joining\n",
    "text_no_nan = text_no_nan.rename(columns={'beer_id':'id'})\n",
    "# subset out retired beers\n",
    "current_beers = beers.loc[beers['retired'] == 'f']\n",
    "# merge text_no_nan with beers that are not retired\n",
    "df = pd.merge(text_no_nan, current_beers, on='id')\n",
    "# create a table with average ratings for each beer. Index/ID is the beer id\n",
    "ratings = pd.DataFrame(df.groupby('id')['score'].mean())\n",
    "# add a column tallying the # of reviews for that beer\n",
    "ratings['no_of_ratings'] = df.groupby('id')['score'].count()\n",
    "# subset ratings with only beers that have 10+ ratings\n",
    "ratings = ratings.loc[ratings['no_of_ratings'] > 9]\n",
    "# formatting\n",
    "ratings = ratings.reset_index()\n",
    "ratings = ratings.rename(columns={'score':'avg_score'})\n",
    "# rejoin no of ratings onto df\n",
    "df = df.merge(ratings, how='inner', on='id')\n",
    "# make a dataframe of reviewers by usename, count the number of reviews they made\n",
    "reviewers = pd.DataFrame(df.groupby('username')['id'].count())\n",
    "# make a new feature, the average of all of their scores\n",
    "reviewers['avg_usr_score'] = df.groupby('username')['score'].mean()\n",
    "# subset reviewers to those with 5+ reviews. From 73k users to 25k.\n",
    "reviewers = reviewers.loc[reviewers['id'] > 4] ## MAYBE I CAN PLAY WITH THIS #\n",
    "# formatting \n",
    "reviewers = reviewers.rename(columns={'id':'tot_usr_rvw'})\n",
    "# there's ~1400 users outsides of 2 STDs of the mean score, will subset them out\n",
    "reviewers_sub = reviewers.loc[(reviewers['avg_usr_score'] >= 3.182) &\\\n",
    "                              (reviewers['avg_usr_score'] <= 4.665)]\n",
    "\n",
    "# subset of df with beers that have 10+ reviews, and with reviewers that have 5+ reviews\n",
    "# and an average rating of beers between 3.18 and 4.67\n",
    "df_with_mins = df.merge(reviewers_sub, how = 'inner', on = 'username')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DKB-aoHWJ5wF"
   },
   "source": [
    "Content Based NLP Stuff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BLQBIoNLJ8Z6"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "from sklearn.feature_extraction import text\n",
    "from gensim.parsing.preprocessing import STOPWORDS as stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HNsi5cDWKRdc"
   },
   "outputs": [],
   "source": [
    "# subsets reviews df, and then joins all text reviews for each individual beer together\n",
    "df_joined = df_with_mins.copy()\n",
    "df_joined['joined_text'] = df_joined.groupby('id')['text'].\\\n",
    "                               transform(lambda x: ''.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IAh8KmW2KVeL"
   },
   "outputs": [],
   "source": [
    "# removes duplicate beers, and subsets to just beer id, joined_text and rating info\n",
    "# to be cleaned and then joined to beers df\n",
    "df_joined_sub = df_joined[['id', 'joined_text', 'avg_score', 'no_of_ratings']].drop_duplicates(\\\n",
    "                                                                        subset='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JnIVdx1mKXPM"
   },
   "outputs": [],
   "source": [
    "# removes \\xa0 remove text\n",
    "df_joined_sub['joined_text'] = df_joined_sub['joined_text'].apply(lambda x: re.sub\\\n",
    "                                                                  (r'\\xa0', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "breweries_sub = breweries[['id','name', 'city', 'state', 'country']]\n",
    "breweries_sub = breweries_sub.rename(columns={'id':'brewery_id', 'name':'brewery_name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "beers_sub = beers[['id', 'name', 'brewery_id', 'style', 'abv']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "breweries_beer = pd.merge(beers_sub, breweries_sub, on = 'brewery_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = pd.merge(df_joined_sub, breweries_beer, on = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.to_pickle(\"./joined_text_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7kQ3_3M5Kavs"
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(stop_words='english')\n",
    "counts = count_vect.fit_transform(df_joined_sub.joined_text)\n",
    "cos_sim = cosine_similarity(counts, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5wEc-zNiKiA2"
   },
   "outputs": [],
   "source": [
    "indices = pd.Series(df_joined_sub.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cos_sim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-d7366677f387>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mrecommendations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeer_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcos_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcos_sim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \"\"\"\n\u001b[1;32m      3\u001b[0m     \u001b[0mTakes\u001b[0m \u001b[0ma\u001b[0m \u001b[0mbeer\u001b[0m \u001b[0mid\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcosine\u001b[0m \u001b[0msimilarty\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0marguments\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mbeers\u001b[0m \u001b[0mclosely\u001b[0m \u001b[0mrelated\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m \u001b[0mbeer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# initializing the empty list of recommended movies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cos_sim' is not defined"
     ]
    }
   ],
   "source": [
    "def recommendations(beer_id, df, cos_sim = cos_sim):\n",
    "    \"\"\"\n",
    "    Takes a beer id and cosine similarty matrix in as arguments and returns beers closely related to the input beer\n",
    "    \"\"\"\n",
    "    # initializing the empty list of recommended movies\n",
    "    recommended_beers = []\n",
    "    \n",
    "    # gettin the index of the movie that matches the title\n",
    "    idx = indices[indices == beer_id].index[0]\n",
    "    \n",
    "    # creating a Series with the similarity scores in descending order\n",
    "    score_series = pd.Series(cos_sim[idx]).sort_values(ascending = False)\n",
    "\n",
    "    # getting the indexes of the 10 most similar movies\n",
    "    top_10_indexes = list(score_series.iloc[1:11].index)\n",
    "    print(top_10_indexes)\n",
    "    # populating the list with the titles of the best 10 matching movies\n",
    "    for i in top_10_indexes:\n",
    "        recommended_beers.append(list(joined_df.name)[i])\n",
    "        \n",
    "    return recommended_beers\n",
    "\n",
    "def tfidf_recs(beer_id, cos_sim = tfidf_cos):\n",
    "    \"\"\"\n",
    "    Takes a beer id and cosine similarty matrix in as arguments and returns beers closely related to the input beer\n",
    "    \"\"\"\n",
    "    # initializing the empty list of recommended movies\n",
    "    recommended_beers = []\n",
    "    \n",
    "    # gettin the index of the movie that matches the title\n",
    "    idx = indices[indices == beer_id].index[0]\n",
    "\n",
    "    # creating a Series with the similarity scores in descending order\n",
    "    score_series = pd.Series(cos_sim[idx]).sort_values(ascending = False)\n",
    "\n",
    "    # getting the indexes of the 10 most similar movies\n",
    "    top_10_indexes = list(score_series.iloc[1:21].index)\n",
    "    \n",
    "    # populating the list with the titles of the best 10 matching movies\n",
    "    for i in top_10_indexes:\n",
    "        recommended_beers.append(list(beers_text.name)[i])\n",
    "        \n",
    "    return beers_text.name[beer_id], recommended_beers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>joined_text</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>no_of_ratings</th>\n",
       "      <th>name</th>\n",
       "      <th>brewery_id</th>\n",
       "      <th>style</th>\n",
       "      <th>abv</th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16302</th>\n",
       "      <td>65010</td>\n",
       "      <td>Consumed 4/13/12 Appearance: Dark caramel/lig...</td>\n",
       "      <td>3.607619</td>\n",
       "      <td>42</td>\n",
       "      <td>Perfect Tin Amber</td>\n",
       "      <td>24488</td>\n",
       "      <td>American Amber / Red Ale</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Tin Roof Brewing Company</td>\n",
       "      <td>Baton Rouge</td>\n",
       "      <td>LA</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                        joined_text  avg_score  \\\n",
       "16302  65010   Consumed 4/13/12 Appearance: Dark caramel/lig...   3.607619   \n",
       "\n",
       "       no_of_ratings               name  brewery_id                     style  \\\n",
       "16302             42  Perfect Tin Amber       24488  American Amber / Red Ale   \n",
       "\n",
       "       abv              brewery_name         city state country  \n",
       "16302  4.5  Tin Roof Brewing Company  Baton Rouge    LA      US  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "RE_PUNCT = re.compile('([%s])+' % re.escape(string.punctuation), re.UNICODE)\n",
    "\n",
    "def preprocess(text):\n",
    "    # Remove all punctuation and make all lowercase \n",
    "    return RE_PUNCT.sub(\" \", text).lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOC2VEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec, Phrases\n",
    "from gensim.parsing.preprocessing import STOPWORDS as stop_words\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = list('abcdefghijklmnopqrstuvwxyz')\n",
    "numbers = list('123456789')\n",
    "\n",
    "stop_words = stop_words.union(set(letters)).union(set(numbers))\n",
    "my_stop_words = text.ENGLISH_STOP_WORDS.union(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_docs(docs, col):\n",
    "    tagged = docs.apply(lambda r: TaggedDocument(words=simple_preprocess(r[col]), tags=docs['id']), axis=1)\n",
    "    return tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged = tag_docs(joined_df, 'joined_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "NLP_stuff.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
